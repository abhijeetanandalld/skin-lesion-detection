{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nQrhE_eU54qU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters.rank import entropy\n",
    "from scipy import ndimage as nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ssm5-nfa6Kq9",
    "outputId": "6cb2a5c4-5f6e-4fda-8114-c61529549ba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(r'D:\\mini-project\\data\\Ready Data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1WLBVVs6Kt2",
    "outputId": "8cf087a5-a159-4f1f-ddb5-1cb166440d91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\mini-project\\data\\Ready Data\\train\\AK\n",
      "D:\\mini-project\\data\\Ready Data\\train\\BCC\n",
      "D:\\mini-project\\data\\Ready Data\\train\\MEL\n",
      "D:\\mini-project\\data\\Ready Data\\train\\VASC\n"
     ]
    }
   ],
   "source": [
    "#Resize images to\n",
    "SIZE = (128,128)\n",
    "\n",
    "#Capture images and labels into arrays.\n",
    "train_images = []\n",
    "train_labels = []\n",
    "for directory_path in glob.glob(r\"D:\\mini-project\\data\\Ready Data\\train\\*\"):\n",
    "    label = directory_path.split(\"/\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path,\"*.*\")):\n",
    "        #print(img_path)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR) #Reading color images\n",
    "        img = cv2.resize(img, (SIZE)) #Resize images\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #Optional step. Change BGR to RGB\n",
    "        train_images.append(img)\n",
    "        train_labels.append(label)\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_FsFf0Z6KwM",
    "outputId": "872754b2-5197-4253-dc6d-1d573fe48324"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 128, 128, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrK-eNVi6K07",
    "outputId": "608af3a9-ffff-4680-9717-48f11f9857ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\mini-project\\data\\Ready Data\\test\\AK\n",
      "D:\\mini-project\\data\\Ready Data\\test\\BCC\n",
      "D:\\mini-project\\data\\Ready Data\\test\\MEL\n",
      "D:\\mini-project\\data\\Ready Data\\test\\VASC\n"
     ]
    }
   ],
   "source": [
    "#Do exactly the same for test/validation images\n",
    "test_images = []\n",
    "test_labels = []\n",
    "for directory_path in glob.glob(r\"D:\\mini-project\\data\\Ready Data\\test\\*\"):\n",
    "    true_label = directory_path.split(\"/\")[-1]\n",
    "    print(true_label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path,\"*.*\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (SIZE))\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #Optional\n",
    "        test_images.append(img)\n",
    "        test_labels.append(true_label)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56_kkS586K3f",
    "outputId": "e4d20b07-69c1-4126-f504-094f1c6841e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 128, 128, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TkVcd_jW6K6B",
    "outputId": "c0820c97-f7fe-410a-d339-59cc334a3519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "#Encode labels from text (folder names) to integers.\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "\n",
    "print(np.unique(train_labels_encoded))\n",
    "print(np.unique(test_labels_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AQIGLjne6K8J"
   },
   "outputs": [],
   "source": [
    "#Split data into test and train datasets (already split but assigning to meaningful convention)\n",
    "#If you only have one dataset then split here\n",
    "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "G9yWGey_ZqEt"
   },
   "outputs": [],
   "source": [
    "def feature_extractor(x_train):\n",
    "  count = 1\n",
    "  image_dataset = pd.DataFrame()\n",
    "  for image in range(x_train.shape[0]):\n",
    "    df = pd.DataFrame()\n",
    "    img = x_train[image, :,:,:]\n",
    "    pixel_values = img.reshape(-1)/2255.0\n",
    "    df['Pixel_Value'] = pixel_values\n",
    "    num = 1  #To count numbers up in order to give Gabor features a lable in the data frame\n",
    "    #kernels = []\n",
    "    for theta in range(2):   #Define number of thetas\n",
    "      theta = theta / 4. * np.pi\n",
    "      for sigma in ([1,2]):  #Sigma with Diff no.\n",
    "        for lamda in np.arange(0, np.pi, np.pi / 4):   #Range of wavelengths\n",
    "          for gamma in ([0.5, 1,1.5]):   #Gamma values of 0.05 and 0.5\n",
    "\n",
    "            gabor_label = 'Gabor' + str(num)  #Label Gabor columns as Gabor1, Gabor2, etc.\n",
    "                        #print(gabor_label)\n",
    "            ksize=5 # try with 9 also\n",
    "            kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, 0, ktype=cv2.CV_32F)\n",
    "                        #kernels.append(kernel)\n",
    "                        #Now filter the image and add values to a new column\n",
    "            fimg = cv2.filter2D(img, cv2.CV_8UC3, kernel)\n",
    "            filtered_img = fimg.reshape(-1)/255.0\n",
    "            df[gabor_label] = filtered_img  #Labels columns as Gabor1, Gabor2, etc.\n",
    "            #print(\"added gabor \",num)            #print(gabor_label, ': theta=', theta, ': sigma=', sigma, ': lamda=', lamda, ': gamma=', gamma)\n",
    "            num += 1  #Increment for gabor column label\n",
    "    #GAUSSIAN with sigma=3\n",
    "    gaussian_img = nd.gaussian_filter(img, sigma=3)\n",
    "    gaussian_img1 = gaussian_img.reshape(-1)/255.0\n",
    "    df['Gaussian s3'] = gaussian_img1\n",
    "\n",
    "    #GAUSSIAN with sigma=5\n",
    "    gaussian_img = nd.gaussian_filter(img, sigma=5)\n",
    "    gaussian_img1 = gaussian_img.reshape(-1)/255.0\n",
    "    df['Gaussian s5'] = gaussian_img1\n",
    "\n",
    "    #GAUSSIAN with sigma=7\n",
    "    gaussian_img2 = nd.gaussian_filter(img, sigma=7)\n",
    "    gaussian_img3 = gaussian_img2.reshape(-1)/255.0\n",
    "    df['Gaussian s7'] = gaussian_img3\n",
    "\n",
    "    #MEDIAN with sigma=5\n",
    "    median_img = nd.median_filter(img, size=5)\n",
    "    median_img1 = median_img.reshape(-1)/255.0\n",
    "    df['Median s5'] = median_img1\n",
    "\n",
    "    #MEDIAN with sigma=7\n",
    "    median_img = nd.median_filter(img, size=7)\n",
    "    median_img1 = median_img.reshape(-1)/255.0\n",
    "    df['Median s7'] = median_img1\n",
    "\n",
    "    #VARIANCE with size=3\n",
    "    variance_img = nd.generic_filter(img, np.var, size=3)\n",
    "    variance_img1 = variance_img.reshape(-1)/255.0\n",
    "    df['Variance s3'] = variance_img1\n",
    "\n",
    "    #VARIANCE with size=5\n",
    "    variance_img = nd.generic_filter(img, np.var, size=5)\n",
    "    variance_img1 = variance_img.reshape(-1)/255.0\n",
    "    df['Variance s5'] = variance_img1\n",
    "    \n",
    "    #VARIANCE with size=7\n",
    "    variance_img = nd.generic_filter(img, np.var, size=7)\n",
    "    variance_img1 = variance_img.reshape(-1)/255.0\n",
    "    df['Variance s7'] = variance_img1\n",
    "    \n",
    "    ''' # Clustering\n",
    "    z = img.reshape((-1,3))\n",
    "    z = np.float32(z)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    K = 5\n",
    "    ret,label,center = cv2.kmeans(z,K,None, criteria, 20, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    res2 = res.reshape((img.shape))\n",
    "    res2 = np.uint8(res2)\n",
    "    df['clustering'] = res2.reshape(-1)/255.0\n",
    "    '''\n",
    "\n",
    "    #Append features from current image to the dataset\n",
    "    image_dataset = pd.concat([image_dataset, df])\n",
    "    print(\"Done Image : \",count)\n",
    "    count += 1\n",
    "\n",
    "  return image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fmOP5Lv6LDV",
    "outputId": "64f0b5aa-fc6f-4b01-8bbc-75933b94f94e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Image :  1\n",
      "Done Image :  2\n",
      "Done Image :  3\n",
      "Done Image :  4\n",
      "Done Image :  5\n",
      "Done Image :  6\n",
      "Done Image :  7\n",
      "Done Image :  8\n",
      "Done Image :  9\n",
      "Done Image :  10\n",
      "Done Image :  11\n",
      "Done Image :  12\n",
      "Done Image :  13\n",
      "Done Image :  14\n",
      "Done Image :  15\n",
      "Done Image :  16\n",
      "Done Image :  17\n",
      "Done Image :  18\n",
      "Done Image :  19\n",
      "Done Image :  20\n",
      "Done Image :  21\n",
      "Done Image :  22\n",
      "Done Image :  23\n",
      "Done Image :  24\n",
      "Done Image :  25\n",
      "Done Image :  26\n",
      "Done Image :  27\n",
      "Done Image :  28\n",
      "Done Image :  29\n",
      "Done Image :  30\n",
      "Done Image :  31\n",
      "Done Image :  32\n",
      "Done Image :  33\n",
      "Done Image :  34\n",
      "Done Image :  35\n",
      "Done Image :  36\n",
      "Done Image :  37\n",
      "Done Image :  38\n",
      "Done Image :  39\n",
      "Done Image :  40\n",
      "Done Image :  41\n",
      "Done Image :  42\n",
      "Done Image :  43\n",
      "Done Image :  44\n",
      "Done Image :  45\n",
      "Done Image :  46\n",
      "Done Image :  47\n",
      "Done Image :  48\n",
      "Done Image :  49\n",
      "Done Image :  50\n",
      "Done Image :  51\n",
      "Done Image :  52\n",
      "Done Image :  53\n",
      "Done Image :  54\n",
      "Done Image :  55\n",
      "Done Image :  56\n",
      "Done Image :  57\n",
      "Done Image :  58\n",
      "Done Image :  59\n",
      "Done Image :  60\n",
      "Done Image :  61\n",
      "Done Image :  62\n",
      "Done Image :  63\n",
      "Done Image :  64\n",
      "Done Image :  65\n",
      "Done Image :  66\n",
      "Done Image :  67\n",
      "Done Image :  68\n",
      "Done Image :  69\n",
      "Done Image :  70\n",
      "Done Image :  71\n",
      "Done Image :  72\n",
      "Done Image :  73\n",
      "Done Image :  74\n",
      "Done Image :  75\n",
      "Done Image :  76\n",
      "Done Image :  77\n",
      "Done Image :  78\n",
      "Done Image :  79\n",
      "Done Image :  80\n"
     ]
    }
   ],
   "source": [
    "#Extract features from training images\n",
    "image_features = feature_extractor(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ljzcijSWaYLG",
    "outputId": "4465ad80-a219-4b96-d28d-3c4eed57446d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshape to a vector for Random Forest / SVM training\n",
    "n_features = image_features.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejnw2jMU6LIq",
    "outputId": "a8a55208-0389-4dc2-c199-356cef63ea42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.07095344, 0.        , 0.        , ..., 0.32941176,\n",
       "         0.85098039, 0.38431373],\n",
       "        [0.06208426, 0.        , 0.        , ..., 0.56470588,\n",
       "         0.53333333, 0.50588235],\n",
       "        [0.10554324, 0.        , 0.        , ..., 0.79607843,\n",
       "         0.51372549, 0.99607843],\n",
       "        ...,\n",
       "        [0.06607539, 0.        , 0.        , ..., 0.03137255,\n",
       "         0.65490196, 0.61568627],\n",
       "        [0.06829268, 0.        , 0.        , ..., 0.11372549,\n",
       "         0.49803922, 0.17254902],\n",
       "        [0.08780488, 0.        , 0.        , ..., 1.        ,\n",
       "         0.45098039, 0.19215686]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features = np.expand_dims(image_features, axis=0)\n",
    "image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcMMkHXNapIR",
    "outputId": "20323e45-0ec5-48fd-ee6c-d7d8d6bd18c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3932160, 57)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDp2JPx36LN4",
    "outputId": "6aa77b56-f73e-4116-d4a9-4dc59b6b1c7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 2801664)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_for_RF = np.reshape(image_features, (x_train.shape[0], -1))  #Reshape to #images, features\n",
    "X_for_RF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tB3pQ8v34r98",
    "outputId": "f6994a38-9994-498a-9c1b-e3cf1bd36c3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Image :  1\n",
      "Done Image :  2\n",
      "Done Image :  3\n",
      "Done Image :  4\n",
      "Done Image :  5\n",
      "Done Image :  6\n",
      "Done Image :  7\n",
      "Done Image :  8\n",
      "Done Image :  9\n",
      "Done Image :  10\n",
      "Done Image :  11\n",
      "Done Image :  12\n",
      "Done Image :  13\n",
      "Done Image :  14\n",
      "Done Image :  15\n",
      "Done Image :  16\n",
      "Done Image :  17\n",
      "Done Image :  18\n",
      "Done Image :  19\n",
      "Done Image :  20\n"
     ]
    }
   ],
   "source": [
    "#Extract features from test data and reshape, just like training data\n",
    "test_features = feature_extractor(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "DPLSG9qg4s1n"
   },
   "outputs": [],
   "source": [
    "test_features = np.expand_dims(test_features, axis=0)\n",
    "test_for_RF = np.reshape(test_features, (x_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNtyBx0B4syG",
    "outputId": "f80f6d5d-5c35-4213-da94-040b62729d9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2801664)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_RF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G83gzDRA4svN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ju9TMn62Djz0"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "HlTKEwCW6LRt",
    "outputId": "8375c3f4-b55e-451e-9d74-179a8f0e0d8d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=105, random_state=101)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=105, random_state=101)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=105, random_state=101)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define the classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model = RandomForestClassifier(n_estimators = 105, random_state = 101)\n",
    "\n",
    "# Fit the model on training data\n",
    "RF_model.fit(X_for_RF, y_train) #For sklearn no one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wmZT7xfc6LYY"
   },
   "outputs": [],
   "source": [
    "#Predict on test\n",
    "rf_test_prediction = RF_model.predict(test_for_RF)\n",
    "#Inverse le transform to get original label back.\n",
    "#rf_test_prediction = le.inverse_transform(test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ftRrEPkbqlAk",
    "outputId": "59514498-5295-45f4-e7b9-3fee63205216"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_test_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vi6EnlHb6LbH",
    "outputId": "1788bd34-879e-4e6c-b353-4239c5f7f119"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.75\n"
     ]
    }
   ],
   "source": [
    "#Print overall accuracy\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test, rf_test_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsXXlaT3GWRL",
    "outputId": "6a0ef4d6-a9df-45bc-ca99-318d48b49ea2"
   },
   "outputs": [],
   "source": [
    "rf_test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Piqa71MYGyAm",
    "outputId": "560672cb-75a5-4f09-8f0d-eed4923e8dea"
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 4, metric = 'minkowski', p = 3)\n",
    "classifier.fit(X_for_RF, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(test_for_RF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.45\n"
     ]
    }
   ],
   "source": [
    "#Print overall accuracy\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=72)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=72)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', random_state=72)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the SVM model on the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifierS = SVC(kernel = 'linear', random_state = 72)\n",
    "classifierS.fit(X_for_RF, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predS = classifierS.predict(test_for_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test, y_predS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
